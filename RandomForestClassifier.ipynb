{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhammans/fraud_busters/blob/Manahil2/RandomForestClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idJgkbGNfat2"
      },
      "outputs": [],
      "source": [
        "#import Dependencies\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/fraudTest.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "5jjsc-Npfoqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['Unnamed: 0', 'cc_num', 'merchant',\n",
        "                   'first', 'last', 'street', 'trans_num', 'dob']\n",
        "data_cleaned = data.drop(columns=columns_to_drop, axis=1)\n"
      ],
      "metadata": {
        "id": "cmHE50XK29ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'trans_date_trans_time' to a numeric format (optional)\n",
        "data_cleaned['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time']).astype('int64') // 10**9  # Convert to Unix timestamp\n"
      ],
      "metadata": {
        "id": "j0sSqNhoYiCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode non-numeric columns, including city and state\n",
        "non_numeric_columns = ['category', 'gender', 'job', 'city', 'state']\n",
        "label_encoders = {}\n",
        "for col in non_numeric_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_cleaned[col] = le.fit_transform(data_cleaned[col].astype(str))  # Ensure all data is string before encoding\n",
        "    label_encoders[col] = le\n"
      ],
      "metadata": {
        "id": "y6r7ixSp29uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract target variable and features\n",
        "X = data_cleaned.drop('is_fraud', axis=1)\n",
        "y = data_cleaned['is_fraud']\n"
      ],
      "metadata": {
        "id": "xjhoxisF291D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure all features are numeric\n",
        "print(\"Data types after encoding:\", X.dtypes)\n"
      ],
      "metadata": {
        "id": "wd_UxFuA3FcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "hQELKs-y3FjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "yskg5vbmfpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the first few rows of the processed dataset\n",
        "print(X_train[:5], y_train[:5])\n"
      ],
      "metadata": {
        "id": "N83OrlH-2rLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training a Random Forest Model**"
      ],
      "metadata": {
        "id": "qqCOU_5B3sS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Re-train and evaluate the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "_LZxCoNnfqZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Analysis of Random Forest Model\n",
        "\n",
        "The Random Forest model performed exceptionally well in terms of overall accuracy, achieving **99.83% accuracy**. However, let's dive deeper into the results:\n",
        "\n",
        "\n",
        "## **Performance Analysis**\n",
        "\n",
        "### **Class 0 (Non-Fraudulent Transactions)**:\n",
        "- **Precision**: 1.00 (Perfect precision; no false positives)\n",
        "- **Recall**: 1.00 (Perfect recall; no false negatives)\n",
        "- **F1-Score**: 1.00 (Excellent balance between precision and recall)\n",
        "\n",
        "### **Class 1 (Fraudulent Transactions)**:\n",
        "- **Precision**: 0.95 (Few false positives)\n",
        "- **Recall**: 0.63 (Moderate recall; missed some fraudulent transactions)\n",
        "- **F1-Score**: 0.76 (Good overall performance for fraud detection, but room for improvement)\n",
        "\n",
        "### **Class Imbalance**\n",
        "- Only **124 fraudulent transactions** vs. **28,613 non-fraudulent transactions**.\n",
        "- This significant imbalance impacts the recall for fraud detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "oQ-TJAIL3dhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adjusting the model's class weights to penalize misclassification of fraudulent transactions.**"
      ],
      "metadata": {
        "id": "qbjgKitr4r5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Initialize the Random Forest model with class weights\n",
        "model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 10})\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "DVp_g-aii7Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Summary\n",
        "\n",
        "### Class 0 (Non-Fraudulent Transactions):\n",
        "- **Precision**: 1.00 (No false positives; perfect identification of non-fraudulent transactions).\n",
        "- **Recall**: 1.00 (All non-fraudulent transactions correctly identified).\n",
        "\n",
        "### Class 1 (Fraudulent Transactions):\n",
        "- **Precision**: 0.95 (Slightly more false positives but still very high).\n",
        "- **Recall**: 0.64 (Improved compared to the previous model, but some fraudulent transactions are still missed).\n",
        "- **F1-Score**: 0.76 (Balanced performance for fraud detection).\n",
        "\n",
        "### Overall Accuracy:\n",
        "- **99.84%**: Excellent overall performance.\n",
        "\n",
        "### Macro and Weighted Averages:\n",
        "- **Macro Avg Recall**: 0.82 (Reflects the imbalanced dataset).\n",
        "- **Weighted Avg Recall**: 1.00 (Dominated by the majority class).\n",
        "\n",
        "## Observations:\n",
        "- The weighted averages show near-perfect results due to the dominant majority class (non-fraudulent transactions).\n"
      ],
      "metadata": {
        "id": "L0umZfmdjwC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Manual Oversampling the data to get maximum accuracy**"
      ],
      "metadata": {
        "id": "a4ta9voz5rHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the majority and minority classes\n",
        "minority_class = data_cleaned[data_cleaned['is_fraud'] == 1]\n",
        "majority_class = data_cleaned[data_cleaned['is_fraud'] == 0]"
      ],
      "metadata": {
        "id": "X7LTB4on49Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Oversample the minority class\n",
        "oversampled_minority_class = minority_class.sample(n=len(majority_class), replace=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "09QF6hZL49Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine the majority class with the oversampled minority class\n",
        "balanced_data = pd.concat([majority_class, oversampled_minority_class])\n"
      ],
      "metadata": {
        "id": "NQt8O45L49jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Shuffle the balanced dataset\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "RFi7agTs5HKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split features and target variable\n",
        "X_balanced = balanced_data.drop('is_fraud', axis=1)\n",
        "y_balanced = balanced_data['is_fraud']\n"
      ],
      "metadata": {
        "id": "BR8O2b8p5HNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_balanced_scaled = scaler.fit_transform(X_balanced)\n"
      ],
      "metadata": {
        "id": "YwjESCeBi7m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced_scaled, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify the class distribution\n",
        "print(\"Class distribution in y_train:\\n\", y_train.value_counts())\n"
      ],
      "metadata": {
        "id": "oz0Bnrj15MC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest Classifier on Balanced Dataset**"
      ],
      "metadata": {
        "id": "fQl4x9Ml5UZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "0sPYXGv9i7qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Summary\n",
        "\n",
        "## **Overall Accuracy**\n",
        "- **99.97%**: Almost perfect accuracy on the balanced dataset.\n",
        "\n",
        "\n",
        "\n",
        "## **Class 0 (Non-Fraudulent Transactions)**\n",
        "- **Precision**: 1.00 (No false positives).\n",
        "- **Recall**: 1.00 (All non-fraudulent transactions correctly identified).\n",
        "- **F1-Score**: 1.00 (Perfect balance between precision and recall).\n",
        "\n",
        "\n",
        "\n",
        "## **Class 1 (Fraudulent Transactions)**\n",
        "- **Precision**: 1.00 (Almost no false positives).\n",
        "- **Recall**: 1.00 (All fraudulent transactions correctly identified).\n",
        "- **F1-Score**: 1.00 (Perfect fraud detection).\n",
        "\n",
        "\n",
        "## **Macro and Weighted Averages**\n",
        "- **Precision, Recall, F1-Score**: All metrics are perfect due to the balanced dataset and model sensitivity.\n",
        "\n",
        "\n",
        "\n",
        "## **Observations**\n",
        "1. **Balanced Data**:\n",
        "   - Balancing the dataset allowed the model to perform equally well for both classes.\n",
        "\n",
        "2. **No Overfitting**:\n",
        "   - Random oversampling combined with the Random Forest model handled the dataset effectively without signs of overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "qk1unhZs5299"
      }
    }
  ]
}