{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHWluTjdoEmE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Find the latest version of spark and enter as the spark version\n",
        "# spark_version = 'spark-3.5.1'\n",
        "spark_version = 'spark-3.5.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik92s2qWoiFD"
      },
      "outputs": [],
      "source": [
        "# Import pyspark packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType, IntegerType\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMKF-SQi30Oj"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version of Kaggle dataset\n",
        "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "\n",
        "# List all files in the downloaded directory\n",
        "files = os.listdir(path)\n",
        "print(\"Files in the dataset:\", files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "kYWegO8OnBiP"
      },
      "outputs": [],
      "source": [
        "# File location and type\n",
        "file_location = path + \"/fraudTrain.csv\"\n",
        "file_type = \"csv\"\n",
        "\n",
        "# CSV options\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \",\"\n",
        "\n",
        "# The applied options are for CSV files. For other file types, these will be ignored.\n",
        "df = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(file_location)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "JcjKV55mnBiQ"
      },
      "outputs": [],
      "source": [
        "# Create a view or table\n",
        "temp_table_name = \"fraudTrain\"\n",
        "\n",
        "df.createOrReplaceTempView(temp_table_name)\n",
        "\n",
        "spark.sql(\"\"\"select * from fraudTrain\"\"\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYW4mfO2OmL_"
      },
      "outputs": [],
      "source": [
        "# Convert unix_time to timestamp to see if it is the same as trans_date_trans_time\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    cc_num,\n",
        "    unix_time,\n",
        "    trans_date_trans_time,\n",
        "    from_unixtime(unix_time + 220924800) unix_convert,\n",
        "    is_fraud,\n",
        "    CASE\n",
        "        WHEN from_unixtime(unix_time + 220924800) = trans_date_trans_time THEN 'Match'\n",
        "        ELSE 'Mismatch'\n",
        "    END as comparison_result\n",
        "FROM fraudTrain\n",
        "order by cc_num,trans_date_trans_time, is_fraud\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0b434c2e-a0c7-4b13-b051-12595fcdef30",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "nJb7HD_onBiR"
      },
      "outputs": [],
      "source": [
        "# Write DataFrame to Parquet with partitioning by a column (e.g., 'is_fraud')\n",
        "df.write.mode(\"overwrite\").partitionBy(\"is_fraud\").parquet(\"fraud_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "db9631f6-bb4a-42ca-8a3c-0d48af932331",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ghXVdJ3znBiS"
      },
      "outputs": [],
      "source": [
        "# Read in our new parquet formatted data\n",
        "p_df=spark.read.parquet('fraud_train')\n",
        "p_df.createOrReplaceTempView('p_fraudTrain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "aae5d0ee-c7b3-490d-bbbc-9b331119a966",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "HTe3IjE_nBiS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Get min, max, avg amounts and counts of transactions\n",
        "start_time = time.time()\n",
        "spark.sql(\"\"\"select is_fraud,\n",
        "                    round(avg(amt),2),\n",
        "                    round(min(amt),2),\n",
        "                    round(max(amt),2),\n",
        "                    round(count(amt),2)\n",
        "            from p_fraudTrain\n",
        "            group by is_fraud\"\"\").show(truncate=False)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyagWm9fSDuD"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from geopy.distance import geodesic  # To calculate distance\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RttstDoUSPdI"
      },
      "outputs": [],
      "source": [
        "fraud_query = \"select cc_num, amt, trans_date_trans_time, lat, long, merchant, merch_lat, merch_long from p_fraudTrain where is_fraud == 1\"\n",
        "spark_fraud_df = spark.sql(fraud_query)\n",
        "\n",
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "fraudulent_transactions_df = spark_fraud_df.toPandas()\n",
        "\n",
        "# Display the Pandas DataFrame\n",
        "fraudulent_transactions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXUAN3fNS0wk"
      },
      "outputs": [],
      "source": [
        "def calculate_distance(row):\n",
        "    transaction_coords = (row[\"lat\"], row[\"long\"])\n",
        "    merchant_coords = (row[\"merch_lat\"], row[\"merch_long\"])\n",
        "    return geodesic(transaction_coords, merchant_coords).km\n",
        "\n",
        "# Add a distance column\n",
        "fraudulent_transactions_df[\"distance_km\"] = fraudulent_transactions_df.apply(calculate_distance, axis=1)\n",
        "\n",
        "fraudulent_transactions_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ajYbQiWS9RY"
      },
      "outputs": [],
      "source": [
        "# Unique credit card numbers for the dropdown\n",
        "cc_nums = fraudulent_transactions_df[\"cc_num\"].unique()\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=cc_nums,\n",
        "    description=\"Credit Card:\",\n",
        "    value=cc_nums[0],\n",
        ")\n",
        "\n",
        "# Function to create the map for a selected credit card number\n",
        "def create_map(cc_num):\n",
        "    filtered_df = fraudulent_transactions_df[fraudulent_transactions_df[\"cc_num\"] == cc_num]\n",
        "\n",
        "    # Initialize the map\n",
        "    if not filtered_df.empty:\n",
        "        map_center = [filtered_df.iloc[0][\"lat\"], filtered_df.iloc[0][\"long\"]]\n",
        "        fraud_map = folium.Map(location=map_center, zoom_start=10)\n",
        "\n",
        "        # Add markers and lines\n",
        "        for _, row in filtered_df.iterrows():\n",
        "            # Customer home location\n",
        "            folium.Marker(\n",
        "                location=[row[\"lat\"], row[\"long\"]],\n",
        "                popup=f\"Customer\",\n",
        "                icon=folium.Icon(color=\"blue\"),\n",
        "            ).add_to(fraud_map)\n",
        "\n",
        "            # Merchant location\n",
        "            folium.Marker(\n",
        "                location=[row[\"merch_lat\"], row[\"merch_long\"]],\n",
        "                popup=f\"Merchant: {row['merchant']}<br>Distance: {0.62137 * row['distance_km']:.2f} miles<br>Amount: ${row['amt']:,.2f}\",\n",
        "                icon=folium.Icon(color=\"green\"),\n",
        "            ).add_to(fraud_map)\n",
        "\n",
        "            # Draw a line between customer home and merchant\n",
        "            folium.PolyLine(\n",
        "                locations=[(row[\"lat\"], row[\"long\"]), (row[\"merch_lat\"], row[\"merch_long\"])],\n",
        "                color=\"red\",\n",
        "                weight=2,\n",
        "            ).add_to(fraud_map)\n",
        "\n",
        "        # Display the map\n",
        "        return fraud_map\n",
        "    else:\n",
        "        return folium.Map(location=[0, 0], zoom_start=2)\n",
        "\n",
        "# Function to update the map when the dropdown changes\n",
        "def update_map(change):\n",
        "    selected_cc_num = change[\"new\"]\n",
        "    map_display.clear_output()\n",
        "    with map_display:\n",
        "        fraud_map = create_map(selected_cc_num)\n",
        "        # fraud_map.save(\"fraud_map.html\")\n",
        "        display(fraud_map)\n",
        "\n",
        "# Display the map with the initial credit card number\n",
        "map_display = widgets.Output()\n",
        "with map_display:\n",
        "    display(create_map(cc_nums[0]))\n",
        "\n",
        "# Update the map when a new credit card number is selected\n",
        "dropdown.observe(update_map, names=\"value\")\n",
        "\n",
        "# Display the dropdown and map\n",
        "display(dropdown, map_display)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mCRF63P61P8"
      },
      "outputs": [],
      "source": [
        "# Extract hour and day\n",
        "fraudulent_transactions_df[\"hour\"] = fraudulent_transactions_df[\"trans_date_trans_time\"].dt.hour\n",
        "fraudulent_transactions_df[\"weekday\"] = fraudulent_transactions_df[\"trans_date_trans_time\"].dt.day_name()\n",
        "\n",
        "# Define the order of weekdays\n",
        "weekday_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "\n",
        "# Aggregate the count of frauds by weekday and hour\n",
        "heatmap_data = fraudulent_transactions_df.groupby([\"weekday\", \"hour\"]).size().reset_index(name=\"count\")\n",
        "\n",
        "# Pivot for heatmap format\n",
        "heatmap_pivot = heatmap_data.pivot(index=\"weekday\", columns=\"hour\", values=\"count\").fillna(0).reindex(weekday_order)\n",
        "\n",
        "# Plot the heat map\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(heatmap_pivot, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Fraud Count'})\n",
        "plt.title(\"Heat Map of Fraudulent Transactions by Weekday and Hour\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.ylabel(\"Weekday\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AJIlPuTc-cY"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"select cc_num, amt, zip, lat, long, city_pop, trans_date_trans_time,\n",
        "                  unix_time, merch_lat, merch_long, category, gender, job, city,\n",
        "                  state, is_fraud\n",
        "           from p_fraudTrain\"\"\"\n",
        "spark_df = spark.sql(query)\n",
        "\n",
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "data_cleaned = spark_df.toPandas()\n",
        "\n",
        "# Display the Pandas DataFrame\n",
        "data_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import Dependencies\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "cqAKZSghHX_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0sSqNhoYiCC"
      },
      "outputs": [],
      "source": [
        "# Convert 'trans_date_trans_time' to a numeric format (optional)\n",
        "data_cleaned['trans_date_trans_time'] = pd.to_datetime(data_cleaned['trans_date_trans_time']).astype('int64') // 10**9  # Convert to Unix timestamp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6r7ixSp29uT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode non-numeric columns, including city and state\n",
        "non_numeric_columns = ['category', 'gender', 'job', 'city', 'state']\n",
        "label_encoders = {}\n",
        "for col in non_numeric_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_cleaned[col] = le.fit_transform(data_cleaned[col].astype(str))  # Ensure all data is string before encoding\n",
        "    label_encoders[col] = le\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjhoxisF291D"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Extract target variable and features\n",
        "X = data_cleaned.drop('is_fraud', axis=1)\n",
        "y = data_cleaned['is_fraud']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd_UxFuA3FcC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensure all features are numeric\n",
        "print(\"Data types after encoding:\", X.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQELKs-y3FjV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yskg5vbmfpVV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N83OrlH-2rLZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Display the first few rows of the processed dataset\n",
        "print(X_train[:5], y_train[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqCOU_5B3sS_"
      },
      "source": [
        "## **Training a Random Forest Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LZxCoNnfqZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Re-train and evaluate the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ-TJAIL3dhN"
      },
      "source": [
        "# Performance Analysis of Random Forest Model\n",
        "\n",
        "The Random Forest model performed exceptionally well in terms of overall accuracy, achieving **99.83% accuracy**. However, let's dive deeper into the results:\n",
        "\n",
        "\n",
        "## **Performance Analysis**\n",
        "\n",
        "### **Class 0 (Non-Fraudulent Transactions)**:\n",
        "- **Precision**: 1.00 (Perfect precision; no false positives)\n",
        "- **Recall**: 1.00 (Perfect recall; no false negatives)\n",
        "- **F1-Score**: 1.00 (Excellent balance between precision and recall)\n",
        "\n",
        "### **Class 1 (Fraudulent Transactions)**:\n",
        "- **Precision**: 0.92 (Few false positives)\n",
        "- **Recall**: 0.68 (Moderate recall; missed some fraudulent transactions)\n",
        "- **F1-Score**: 0.78 (Good overall performance for fraud detection, but room for improvement)\n",
        "\n",
        "### **Class Imbalance**\n",
        "- Only **7,506 fraudulent transactions** vs. **1,289,169 non-fraudulent transactions**.\n",
        "- This significant imbalance impacts the recall for fraud detection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbjgKitr4r5k"
      },
      "source": [
        "## **Adjusting the model's class weights to penalize misclassification of fraudulent transactions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVp_g-aii7Ud"
      },
      "outputs": [],
      "source": [
        "# Initialize the Random Forest model with class weights\n",
        "model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 10})\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0umZfmdjwC2"
      },
      "source": [
        "# Performance Summary\n",
        "\n",
        "### Class 0 (Non-Fraudulent Transactions):\n",
        "- **Precision**: 1.00 (No false positives; perfect identification of non-fraudulent transactions).\n",
        "- **Recall**: 1.00 (All non-fraudulent transactions correctly identified).\n",
        "\n",
        "### Class 1 (Fraudulent Transactions):\n",
        "- **Precision**: 0.94 (Slightly more false positives but still very high).\n",
        "- **Recall**: 0.67 (Improved compared to the previous model, but some fraudulent transactions are still missed).\n",
        "- **F1-Score**: 0.78 (Balanced performance for fraud detection).\n",
        "\n",
        "### Overall Accuracy:\n",
        "- **99.84%**: Excellent overall performance.\n",
        "\n",
        "### Macro and Weighted Averages:\n",
        "- **Macro Avg Recall**: 0.84 (Reflects the imbalanced dataset).\n",
        "- **Weighted Avg Recall**: 1.00 (Dominated by the majority class).\n",
        "\n",
        "## Observations:\n",
        "- The weighted averages show near-perfect results due to the dominant majority class (non-fraudulent transactions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ta9voz5rHZ"
      },
      "source": [
        "## **Manual Oversampling the data to get maximum accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7LTB4on49Sm"
      },
      "outputs": [],
      "source": [
        "# Separate the majority and minority classes\n",
        "minority_class = data_cleaned[data_cleaned['is_fraud'] == 1]\n",
        "majority_class = data_cleaned[data_cleaned['is_fraud'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09QF6hZL49Zo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Oversample the minority class\n",
        "oversampled_minority_class = minority_class.sample(n=len(majority_class), replace=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQt8O45L49jA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Combine the majority class with the oversampled minority class\n",
        "balanced_data = pd.concat([majority_class, oversampled_minority_class])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFi7agTs5HKX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Shuffle the balanced dataset\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR8O2b8p5HNu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split features and target variable\n",
        "X_balanced = balanced_data.drop('is_fraud', axis=1)\n",
        "y_balanced = balanced_data['is_fraud']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwjESCeBi7m7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_balanced_scaled = scaler.fit_transform(X_balanced)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz0Bnrj15MC2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced_scaled, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify the class distribution\n",
        "print(\"Class distribution in y_train:\\n\", y_train.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQl4x9Ml5UZg"
      },
      "source": [
        "## **Random Forest Classifier on Balanced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sPYXGv9i7qS"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk1unhZs5299"
      },
      "source": [
        "# Performance Summary\n",
        "\n",
        "## **Overall Accuracy**\n",
        "- **99.97%**: Almost perfect accuracy on the balanced dataset.\n",
        "\n",
        "\n",
        "\n",
        "## **Class 0 (Non-Fraudulent Transactions)**\n",
        "- **Precision**: 1.00 (No false positives).\n",
        "- **Recall**: 1.00 (All non-fraudulent transactions correctly identified).\n",
        "- **F1-Score**: 1.00 (Perfect balance between precision and recall).\n",
        "\n",
        "\n",
        "\n",
        "## **Class 1 (Fraudulent Transactions)**\n",
        "- **Precision**: 1.00 (Almost no false positives).\n",
        "- **Recall**: 1.00 (All fraudulent transactions correctly identified).\n",
        "- **F1-Score**: 1.00 (Perfect fraud detection).\n",
        "\n",
        "\n",
        "## **Macro and Weighted Averages**\n",
        "- **Precision, Recall, F1-Score**: All metrics are perfect due to the balanced dataset and model sensitivity.\n",
        "\n",
        "\n",
        "\n",
        "## **Observations**\n",
        "1. **Balanced Data**:\n",
        "   - Balancing the dataset allowed the model to perform equally well for both classes.\n",
        "\n",
        "2. **No Overfitting**:\n",
        "   - Random oversampling combined with the Random Forest model handled the dataset effectively without signs of overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forests in sklearn will automatically calculate feature importance\n",
        "importances = model.feature_importances_\n",
        "# We can sort the features by their importance\n",
        "sorted(zip(model.feature_importances_, X.columns), reverse=True)\n",
        "\n",
        " # Visualize the features by importance\n",
        "importances_df = pd.DataFrame(sorted(zip(model.feature_importances_, X.columns), reverse=True))\n",
        "importances_df.set_index(importances_df[1], inplace=True)\n",
        "importances_df.drop(columns=1, inplace=True)\n",
        "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
        "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
        "importances_sorted.plot(kind='barh', color='lightgreen', title= 'Features Importances', legend=False)"
      ],
      "metadata": {
        "id": "2KPTkysTz30k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the features in the correct order based on training\n",
        "input_features = [\n",
        "    \"cc_num\", \"amt\", \"zip\", \"lat\", \"long\", \"city_pop\",\n",
        "    \"trans_date_trans_time\", \"unix_time\", \"merch_lat\", \"merch_long\",\n",
        "    \"category\", \"gender\", \"job\", \"city\", \"state\"\n",
        "]\n",
        "\n",
        "# Collect user input for only essential features\n",
        "user_inputs = []\n",
        "print(\"Please enter the values for the required features:\")\n",
        "amt = float(input(\"Enter value for amt: \"))\n",
        "category = float(input(\"Enter transaction category (0-13): \"))\n",
        "date = str(input(\"Enter transaction date (YYYY-MM-DD): \"))\n",
        "time = str(input(\"Enter transaction time (HH:MM): \"))\n",
        "\n",
        "# Combine date and time to datetime object\n",
        "datetime_str = f\"{date} {time}\"\n",
        "dt_object = datetime.strptime(datetime_str, \"%Y-%m-%d %H:%M\")\n",
        "\n",
        "# Convert datetime to Unix timestamp\n",
        "unix_time = int(dt_object.timestamp())\n",
        "trans_date_trans_time = int(dt_object.timestamp())\n",
        "\n",
        "# Default values for features including those provided by the user\n",
        "default_values = {\n",
        "    \"cc_num\": 3524574586339330, # Default credit card number\n",
        "    \"amt\": amt,\n",
        "    \"zip\": 32960,             # Default zip code\n",
        "    \"lat\": 27.6330,           # Example latitude\n",
        "    \"long\": -80.4031,        # Example longitude\n",
        "    \"city_pop\": 105638,         # Example city population\n",
        "    \"trans_date_trans_time\": trans_date_trans_time,\n",
        "    \"unix_time\": unix_time - 220924800,\n",
        "    \"merch_lat\": 26.888686,   # Example merchant latitude\n",
        "    \"merch_long\": -80.834389, # Example merchant longitude\n",
        "    \"category\": category,\n",
        "    \"gender\": 0,              # Example gender encoding\n",
        "    \"job\": 271,                 # Placeholder for job (encoded as numeric)\n",
        "    \"city\": 829,                # Placeholder for city (encoded as numeric)\n",
        "    \"state\": 9                # Placeholder for state (encoded as numeric)\n",
        "}\n",
        "\n",
        "\n",
        "# Append default values for the remaining features\n",
        "# for feature in input_features[4:]:  # Skip first four features\n",
        "for feature in input_features:\n",
        "    user_inputs.append(default_values[feature])\n",
        "\n",
        "print (f\"trans_date_trans_time: {trans_date_trans_time}\\n unix_time: {unix_time - 220924800}\")\n",
        "\n",
        "# Convert inputs to a model-compatible format\n",
        "input_array = np.array([user_inputs])  # Reshape for prediction\n",
        "\n",
        "# Debugging: Check if input matches expected shape\n",
        "print(f\"Input shape: {input_array.shape}\")\n",
        "print(f\"Model expects: {model.n_features_in_} features\")\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(input_array)\n",
        "\n",
        "# Output the prediction\n",
        "if prediction[0] == 1:\n",
        "    print(\"Prediction: Fraud\")\n",
        "else:\n",
        "    print(\"Prediction: Not Fraud\")"
      ],
      "metadata": {
        "id": "AcIutlbbJm-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns.tolist())\n",
        "print(f\"Training data shape: {X.shape}\")"
      ],
      "metadata": {
        "id": "cDNTUu5O2SpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input shape: {input_array.shape}\")\n",
        "print(f\"Model expects: {model.n_features_in_} features\")"
      ],
      "metadata": {
        "id": "P3zSUfUM2V07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trans_date_trans_time)"
      ],
      "metadata": {
        "id": "0zIdYw5xCvjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender = label_encoders['gender'].inverse_transform([0, 1])\n",
        "print(gender)"
      ],
      "metadata": {
        "id": "Tbj43CIGTVSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaned['category'].value_counts()"
      ],
      "metadata": {
        "id": "zIn409sj6RzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the LabelEncoder for the 'category' column\n",
        "category_encoder = label_encoders['state']\n",
        "\n",
        "# Get the mapping of numerical labels to original categories\n",
        "categories_decoded = {index: label for index, label in enumerate(category_encoder.classes_)}\n",
        "\n",
        "# Print the decoded categories\n",
        "print(\"Decoded Categories:\")\n",
        "for number, category in categories_decoded.items():\n",
        "    print(f\"{number}: {category}\")"
      ],
      "metadata": {
        "id": "SKH6XMPBT7-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the LabelEncoder for the 'category' column\n",
        "category_encoder = label_encoders['job']\n",
        "\n",
        "# Get the mapping of numerical labels to original categories\n",
        "categories_decoded = {index: label for index, label in enumerate(category_encoder.classes_)}\n",
        "\n",
        "# Print the decoded categories\n",
        "print(\"Decoded Categories:\")\n",
        "for number, category in categories_decoded.items():\n",
        "    print(f\"{number}: {category}\")"
      ],
      "metadata": {
        "id": "yPWIQ8q7Tblq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the LabelEncoder for the 'category' column\n",
        "category_encoder = label_encoders['city']\n",
        "\n",
        "# Get the mapping of numerical labels to original categories\n",
        "categories_decoded = {index: label for index, label in enumerate(category_encoder.classes_)}\n",
        "\n",
        "# Print the decoded categories\n",
        "print(\"Decoded Categories:\")\n",
        "for number, category in categories_decoded.items():\n",
        "    print(f\"{number}: {category}\")"
      ],
      "metadata": {
        "id": "Qu-rxvpeT1n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the LabelEncoder for the 'category' column\n",
        "category_encoder = label_encoders['category']\n",
        "\n",
        "# Get the mapping of numerical labels to original categories\n",
        "categories_decoded = {index: label for index, label in enumerate(category_encoder.classes_)}\n",
        "\n",
        "# Print the decoded categories\n",
        "print(\"Decoded Categories:\")\n",
        "for number, category in categories_decoded.items():\n",
        "    print(f\"{number}: {category}\")"
      ],
      "metadata": {
        "id": "EgtdqcqTUm2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": 1227615999916769,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 4
      },
      "notebookName": "credit_card_parquet",
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "nbdime-conflicts": {
      "local_diff": [
        {
          "key": "colab",
          "op": "add",
          "value": {
            "provenance": []
          }
        }
      ],
      "remote_diff": [
        {
          "key": "colab",
          "op": "add",
          "value": {
            "include_colab_link": true,
            "provenance": []
          }
        }
      ]
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}